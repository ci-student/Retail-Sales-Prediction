{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8fe327f",
   "metadata": {},
   "source": [
    "# Regression\n",
    "## Objectives\n",
    "- Fit and evaluate a regression model to predict the sale price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0197b898",
   "metadata": {},
   "source": [
    "We need to change the working directory from its current folder to its parent folder\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9043bf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba17b6",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory\n",
    "* os.path.dirname() gets the parent directory\n",
    "* os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ce64cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c47160",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28d80843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f84231",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bea51a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('outputs/TrainData.csv')\n",
    "validation_data = pd.read_csv('outputs/ValidationData.csv')\n",
    "test_data = pd.read_csv('outputs/TestData.csv')\n",
    "\n",
    "#Drop the \"Date\" column from the training, validation, and test datasets\n",
    "train_data = train_data.drop(columns=['Date'])\n",
    "validation_data = validation_data.drop(columns=['Date'])\n",
    "test_data = test_data.drop(columns=['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c33a3",
   "metadata": {},
   "source": [
    "### Split the data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99e2d97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns='Weekly_Sales')\n",
    "y_train = train_data['Weekly_Sales']\n",
    "\n",
    "X_valid = validation_data.drop(columns='Weekly_Sales')\n",
    "y_valid = validation_data['Weekly_Sales']\n",
    "\n",
    "X_test = test_data.drop(columns='Weekly_Sales')\n",
    "y_test = test_data['Weekly_Sales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967e72a9",
   "metadata": {},
   "source": [
    "### Create ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e67ca35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model):\n",
    "    pipeline = Pipeline([\n",
    "        (\"smart_correlated_selection\", SmartCorrelatedSelection(threshold=0.8)),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40ca446",
   "metadata": {},
   "source": [
    "### Custom Class for Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7abe7cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperparameterOptimizationSearch:\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = create_pipeline(self.models[key])\n",
    "            gs = GridSearchCV(model, self.params[key], cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        return df, self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a59e677",
   "metadata": {},
   "source": [
    "### Grid Search CV - Sklearn (Initial Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee75a76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search = {\n",
    "    'LinearRegression': {},\n",
    "    'DecisionTreeRegressor': {},\n",
    "    'GradientBoostingRegressor':{},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7291401f",
   "metadata": {},
   "source": [
    "Do a hyperparameter optimization search using default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86708052",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
    "search.fit(X_valid, y_valid, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee369b",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afd8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a6d73",
   "metadata": {},
   "source": [
    "Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e2705",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0]['estimator']\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65743f96",
   "metadata": {},
   "source": [
    "Best Parameters for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_pipelines[best_model].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ad9dd0",
   "metadata": {},
   "source": [
    "Define the best regressor, based on the search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8736aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline = grid_search_pipelines[best_model].best_estimator_\n",
    "best_regressor_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9445411",
   "metadata": {},
   "source": [
    "### Assess Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58a19998",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaning_feat_eng_steps = 1\n",
    "columns_after_feat_eng = (Pipeline(best_regressor_pipeline.steps[:data_cleaning_feat_eng_steps])\n",
    "                          .transform(X_train).columns)\n",
    "\n",
    "best_features = columns_after_feat_eng[best_regressor_pipeline['feat_selection'].get_support()].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17afa8f",
   "metadata": {},
   "source": [
    "Plot feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f210231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance = pd.DataFrame({\n",
    "    'Feature': best_features,\n",
    "    'Importance': best_regressor_pipeline['model'].feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c854d5",
   "metadata": {},
   "source": [
    "### Pipeline for MultiLayerPerceptron (can't include feat_selection step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "688c9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_MLP(model):\n",
    "    pipeline = Pipeline([\n",
    "        (\"smart_correlated_selection\", SmartCorrelatedSelection(threshold=0.8)),\n",
    "        (\"feat_scaling\", StandardScaler()),\n",
    "        (\"model\", model)\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "class HyperparameterOptimizationSearchMLP:\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "            model = create_pipeline_MLP(self.models[key])\n",
    "            gs = GridSearchCV(model, self.params[key], cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        return df, self.grid_searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63da147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_quick_search_MLP = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=0),\n",
    "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "    'MLPRegressor': MLPRegressor(random_state=0),\n",
    "}\n",
    "\n",
    "params_quick_search_MLP = {\n",
    "    'LinearRegression': {},\n",
    "    'DecisionTreeRegressor': {},\n",
    "    'GradientBoostingRegressor':{},\n",
    "    'MLPRegressor': {\n",
    "        'model__hidden_layer_sizes': [(4, 2), (6, 3), (8, 4)],  # k = 2, 3, 4\n",
    "        'model__alpha': [0.0001, 0.001, 0.01],\n",
    "        'model__learning_rate_init': [0.001, 0.01, 0.1]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da488ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_MLP = HyperparameterOptimizationSearchMLP(models=models_quick_search_MLP, params=params_quick_search_MLP)\n",
    "search_MLP.fit(X_valid, y_valid, scoring='r2', n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62c599",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary_MLP, grid_search_pipelines_MLP = search_MLP.score_summary(sort_by='mean_score')\n",
    "grid_search_summary_MLP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfafa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_MLP = grid_search_summary_MLP.iloc[0]['estimator']\n",
    "best_model_MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e7aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_regressor_pipeline_MLP = grid_search_pipelines_MLP[best_model_MLP].best_estimator_\n",
    "best_regressor_pipeline_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460b46cd",
   "metadata": {},
   "source": [
    "### Evaluate on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43035572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"Model Evaluation \\n\")\n",
    "    print(\"* Train Set\")\n",
    "    regression_evaluation(X_train, y_train, pipeline)\n",
    "    print(\"* Test Set\")\n",
    "    regression_evaluation(X_test, y_test, pipeline)\n",
    "\n",
    "\n",
    "def regression_evaluation(X, y, pipeline):\n",
    "    prediction = pipeline.predict(X)\n",
    "    print('R2 Score:', r2_score(y, prediction).round(3))\n",
    "    print('Mean Absolute Error:', mean_absolute_error(y, prediction).round(3))\n",
    "    print('Mean Squared Error:', mean_squared_error(y, prediction).round(3))\n",
    "    print('Root Mean Squared Error:', np.sqrt(\n",
    "        mean_squared_error(y, prediction)).round(3))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def regression_evaluation_plots(X_train, y_train, X_test, y_test, pipeline, alpha_scatter=0.5):\n",
    "    pred_train = pipeline.predict(X_train)\n",
    "    pred_test = pipeline.predict(X_test)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(16, 6))\n",
    "    sns.scatterplot(x=y_train, y=pred_train, alpha=alpha_scatter, ax=axes[0])\n",
    "    sns.lineplot(x=y_train, y=y_train, color='red', ax=axes[0])\n",
    "    axes[0].set_xlabel(\"Actual\")\n",
    "    axes[0].set_ylabel(\"Predictions\")\n",
    "    axes[0].set_title(\"Train Set\")\n",
    "\n",
    "    sns.scatterplot(x=y_test, y=pred_test, alpha=alpha_scatter, ax=axes[1])\n",
    "    sns.lineplot(x=y_test, y=y_test, color='red', ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Actual\")\n",
    "    axes[1].set_ylabel(\"Predictions\")\n",
    "    axes[1].set_title(\"Test Set\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f863f3",
   "metadata": {},
   "source": [
    "Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b612da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_performance(X_train, y_train, X_test, y_test,best_regressor_pipeline_MLP)\n",
    "regression_evaluation_plots(X_train, y_train, X_test, y_test, best_regressor_pipeline_MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a439b61",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef7559",
   "metadata": {},
   "source": [
    "As an example we will produce forecast for hte first 3 rows of Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4079b242",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_regressor_pipeline_MLP.predict(X_test.iloc[0:3,:])\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53d5dff",
   "metadata": {},
   "source": [
    "### Push files to the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2dc1bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_sales/{version}'\n",
    "\n",
    "os.makedirs(file_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c11294",
   "metadata": {},
   "source": [
    "Save train, validation, and test sets with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7311ac3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = X_train.filter(best_features)\n",
    "X_test_filtered = X_test.filter(best_features)\n",
    "\n",
    "X_train_filtered.to_csv(f\"{file_path}/X_train.csv\", index=False)\n",
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)\n",
    "X_test_filtered.to_csv(f\"{file_path}/X_test.csv\", index=False)\n",
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3155f24",
   "metadata": {},
   "source": [
    "Save model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac3dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_regressor_pipeline_MLP, f\"{file_path}/pipeline_reg.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a2eff0",
   "metadata": {},
   "source": [
    "Save feature importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51183e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.savefig(f\"{file_path}/features_importance.png\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
